{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "from functools import lru_cache # Import lru_cache\n",
        "\n",
        "# ==============================================================================\n",
        "# 0) CONFIGURATION\n",
        "# ==============================================================================\n",
        "# Define paths for your data and models in Google Drive\n",
        "CLUSTERED_DATA_PATH = '/content/drive/MyDrive/amazon_reviews_clustered_and_categorized.csv'\n",
        "SUMMARIZATION_MODEL_NAME = \"t5-small\" # You can use \"t5-base\" for better quality but slower generation\n",
        "OUTPUT_BLOG_POSTS_DIR = '/content/drive/MyDrive/generated_blog_posts/'\n",
        "\n",
        "# Set device for model inference\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1) MOUNT GOOGLE DRIVE\n",
        "# ==============================================================================\n",
        "print(\"Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    print(\"Please ensure you are running in a Colab environment and authorize access.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2) LOAD DATA AND SUMMARIZATION MODEL\n",
        "# ==============================================================================\n",
        "@lru_cache(maxsize=1)\n",
        "def load_data(path: str) -> pd.DataFrame:\n",
        "    \"\"\"Loads the clustered and categorized Amazon reviews DataFrame.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        # Ensure necessary columns are correctly typed and handle missing values\n",
        "        if 'asin' in df.columns:\n",
        "            df['asin'] = df['asin'].astype(str)\n",
        "        if 'full_review' in df.columns:\n",
        "            df['full_review'] = df['full_review'].astype(str).fillna('')\n",
        "        if 'meta_category' in df.columns:\n",
        "            df['meta_category'] = df['meta_category'].astype(str).fillna('Uncategorized')\n",
        "        if 'sentiment' in df.columns: # Assuming this column exists from sentiment analysis\n",
        "            df['sentiment'] = df['sentiment'].astype(str)\n",
        "        print(f\"DataFrame loaded from {path}. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Data file not found at {path}. Please check the path and ensure the file exists.\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def load_summarization_model(model_name: str):\n",
        "    \"\"\"Loads the T5 summarization model and tokenizer.\"\"\"\n",
        "    print(f\"Loading summarization model: {model_name}...\")\n",
        "    try:\n",
        "        tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
        "        model = T5ForConditionalGeneration.from_pretrained(model_name).to(DEVICE)\n",
        "        print(\"Summarization model and tokenizer loaded successfully.\")\n",
        "        return tokenizer, model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading summarization model: {e}\")\n",
        "        print(\"Please ensure you have an internet connection and the model name is correct.\")\n",
        "        return None, None\n",
        "\n",
        "df_clustered_categorized = load_data(CLUSTERED_DATA_PATH)\n",
        "summarizer_tokenizer, summarizer_model = load_summarization_model(SUMMARIZATION_MODEL_NAME)\n",
        "\n",
        "if df_clustered_categorized.empty or summarizer_tokenizer is None or summarizer_model is None:\n",
        "    print(\"Exiting due to critical loading errors. Please resolve the issues above.\")\n",
        "    exit() # Exit the script if essential components are not loaded\n",
        "\n",
        "# ==============================================================================\n",
        "# 3) PRODUCT RECOMMENDATION LOGIC\n",
        "# ==============================================================================\n",
        "def get_top_products_by_category(df: pd.DataFrame, num_products_per_category: int = 3, min_reviews_threshold: int = 3): # Lowered threshold to 3\n",
        "    \"\"\"\n",
        "    Identifies top products within each meta_category based on the proportion of positive reviews.\n",
        "    Assumes 'full_review' is used for product identification as 'asin' is not available and 'sentiment' (positive/negative).\n",
        "    \"\"\"\n",
        "    print(f\"Identifying top {num_products_per_category} products per category with at least {min_reviews_threshold} reviews...\")\n",
        "    recommendations = {}\n",
        "\n",
        "    for category in df['meta_category'].unique():\n",
        "        category_df = df[df['meta_category'] == category].copy()\n",
        "\n",
        "        if category_df.empty:\n",
        "            continue\n",
        "\n",
        "        # Calculate positive review count and total review count per product, grouping by 'full_review'\n",
        "        product_sentiment = category_df.groupby('full_review').agg(\n",
        "            positive_reviews=('sentiment', lambda x: (x == 'positive').sum()),\n",
        "            total_reviews=('sentiment', 'count')\n",
        "        ).reset_index()\n",
        "\n",
        "        # Calculate the proportion of positive reviews\n",
        "        product_sentiment['positive_ratio'] = product_sentiment['positive_reviews'] / product_sentiment['total_reviews']\n",
        "\n",
        "        # Filter products with at least a minimum number of reviews to ensure significance\n",
        "        reliable_products = product_sentiment[product_sentiment['total_reviews'] >= min_reviews_threshold]\n",
        "\n",
        "        # Sort by positive ratio (and total reviews as a tie-breaker) and get top products\n",
        "        top_products = reliable_products.sort_values(\n",
        "            by=['positive_ratio', 'total_reviews'],\n",
        "            ascending=[False, False]\n",
        "        ).head(num_products_per_category)\n",
        "\n",
        "        if not top_products.empty:\n",
        "            # Store 'full_review' as product identifier since 'asin' is not available\n",
        "            recommendations[category] = top_products.rename(columns={'full_review': 'product_identifier'}).to_dict(orient='records')\n",
        "            print(f\"  Top products for '{category}': {[p['product_identifier'][:50] + '...' for p in recommendations[category]]}\") # Print snippet of review\n",
        "        else:\n",
        "            print(f\"  No reliable top products found for category: '{category}'\")\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "product_recommendations_by_category = get_top_products_by_category(df_clustered_categorized)\n",
        "print(\"\\nGenerated Product Recommendations Summary:\")\n",
        "for cat, products in product_recommendations_by_category.items():\n",
        "    print(f\"- {cat}: {[p['product_identifier'][:50] + '...' for p in products]}\") # Print snippet of review\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4) SUMMARIZATION FUNCTION (ADAPTED FROM main_text_summarization.ipynb)\n",
        "# ==============================================================================\n",
        "def summarize_text(text: str, tokenizer, model, max_length: int = 60, min_length: int = 20) -> str:\n",
        "    \"\"\"\n",
        "    Generates a summary for the given text using the loaded T5 model.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"No summary available.\"\n",
        "    try:\n",
        "        inputs = tokenizer(\n",
        "            \"summarize: \" + text,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512, # Max input length for T5\n",
        "            truncation=True\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        summary_ids = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=max_length,\n",
        "            min_length=min_length,\n",
        "            length_penalty=2.0,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summarization: {e}\")\n",
        "        return \"Failed to generate summary.\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 5) BLOG POST GENERATION\n",
        "# ==============================================================================\n",
        "def generate_blog_post(category: str, recommended_products: list, df_data: pd.DataFrame, tokenizer, model) -> str:\n",
        "    \"\"\"Generates a blog post for a given category and its recommended products.\"\"\"\n",
        "    post_title = f\"ðŸŒŸ Top Picks in {category}: Reviews You Can Trust!\"\n",
        "    post_content = f\"# {post_title}\\n\\n\"\n",
        "    post_content += f\"Looking for the best products in the **{category}** category? We've analyzed thousands of Amazon reviews, leveraged advanced sentiment analysis, and smart clustering to bring you the top-rated items that customers absolutely love. Our deep dive into customer feedback revealed these gems based on overwhelmingly positive experiences!\\n\\n\"\n",
        "    post_content += \"--- \\n\\n\"\n",
        "\n",
        "    for product_info in recommended_products:\n",
        "        # Use the product_identifier from the recommendation dict (which is 'full_review' in this case)\n",
        "        product_identifier = product_info['product_identifier']\n",
        "        # Use a snippet of the review text as a placeholder for product title\n",
        "        product_title = f\"Product based on review: \\\"{product_identifier[:70]}...\\\"\"\n",
        "\n",
        "\n",
        "        # Get relevant positive reviews for summarization - filter by the 'full_review' text used as identifier\n",
        "        product_positive_reviews = df_data[(df_data['full_review'] == product_identifier) & (df_data['sentiment'] == 'positive')]['full_review'].tolist()\n",
        "\n",
        "        post_content += f\"## âœ¨ {product_title}\\n\\n\"\n",
        "        post_content += f\"**Representative Review:** `{product_identifier[:100]}...`\\n\\n\" # Display a longer snippet of the review\n",
        "\n",
        "        if product_positive_reviews:\n",
        "            # Select up to 3 random positive reviews to summarize (will likely be the same review if grouping by full_review)\n",
        "            sample_reviews = random.sample(product_positive_reviews, min(3, len(product_positive_reviews)))\n",
        "            post_content += \"**What customers are saying (summarized highlights):**\\n\\n\"\n",
        "            for review_text in sample_reviews:\n",
        "                summary = summarize_text(review_text, tokenizer, model, max_length=50, min_length=15)\n",
        "                post_content += f\"> \\\"*{summary}*\\\"\\n\\n\"\n",
        "        else:\n",
        "            post_content += \"*(No prominent positive reviews found to highlight with summaries.)*\\n\\n\"\n",
        "\n",
        "        # Add a placeholder link (cannot create a real link without ASIN)\n",
        "        post_content += \"[Link to Product (ASIN not available)]\\n\\n\"\n",
        "        post_content += \"--- \\n\\n\"\n",
        "\n",
        "    post_content += \"We hope these data-driven recommendations empower you to make excellent purchasing decisions. Happy shopping, and may your next Amazon buy be a fantastic one!\\n\"\n",
        "    return post_content\n",
        "\n",
        "print(\"\\nGenerating blog posts...\")\n",
        "generated_blog_posts = {}\n",
        "for category, products_list in product_recommendations_by_category.items():\n",
        "    if products_list: # Only generate if there are recommendations\n",
        "        print(f\"  Generating post for category: '{category}'\")\n",
        "        blog_post_text = generate_blog_post(category, products_list, df_clustered_categorized, summarizer_tokenizer, summarizer_model)\n",
        "        generated_blog_posts[category] = blog_post_text\n",
        "    else:\n",
        "        print(f\"  Skipping post generation for empty category: '{category}'\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 6) SAVE FINAL OUTPUT\n",
        "# ==============================================================================\n",
        "print(\"\\nSaving generated blog posts...\")\n",
        "os.makedirs(OUTPUT_BLOG_POSTS_DIR, exist_ok=True)\n",
        "\n",
        "for category, post_content in generated_blog_posts.items():\n",
        "    # Sanitize category name for filename\n",
        "    safe_category_name = category.replace(' ', '_').replace('/', '_').replace('&', 'and').lower()\n",
        "    file_name = f\"{OUTPUT_BLOG_POSTS_DIR}amazon_recommendations_{safe_category_name}.md\"\n",
        "    with open(file_name, 'w', encoding='utf-8') as f:\n",
        "        f.write(post_content)\n",
        "    print(f\"  Saved blog post for '{category}' to: {file_name}\")\n",
        "\n",
        "print(\"\\nAll blog posts generated and saved successfully!\")\n",
        "print(f\"You can find them in your Google Drive at: {OUTPUT_BLOG_POSTS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz6tkBBqYlnj",
        "outputId": "d631e9ed-6934-4910-a390-120b9015f5b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "DataFrame loaded from /content/drive/MyDrive/amazon_reviews_clustered_and_categorized.csv. Shape: (47295, 5)\n",
            "Loading summarization model: t5-small...\n",
            "Summarization model and tokenizer loaded successfully.\n",
            "Identifying top 3 products per category with at least 3 reviews...\n",
            "  Top products for 'Miscellaneous Electronics': ['Christmas Gift bought fianc cant get enough awesom...', 'Good reader original kindle decided upgrade functi...', 'Good, but one small thing annoys me... purchased u...']\n",
            "  Top products for 'E-readers & Tablets': ['Great for entertainment & e-mail awesome tablet fa...', 'Great tablet bought tablet daughter loves...', 'Great tablet bought tablet fiance daughter getting...']\n",
            "  Top products for 'Smart Home Devices': ['Great, Cost-Effective Echo Device bought amazon ta...', 'Tap purchased tap thought portable speaker echo ac...']\n",
            "  No reliable top products found for category: 'Branded Batteries'\n",
            "  Top products for 'General Batteries': ['Five Stars good...', 'Five Stars great...', 'Five Stars great value...']\n",
            "\n",
            "Generated Product Recommendations Summary:\n",
            "- Miscellaneous Electronics: ['Christmas Gift bought fianc cant get enough awesom...', 'Good reader original kindle decided upgrade functi...', 'Good, but one small thing annoys me... purchased u...']\n",
            "- E-readers & Tablets: ['Great for entertainment & e-mail awesome tablet fa...', 'Great tablet bought tablet daughter loves...', 'Great tablet bought tablet fiance daughter getting...']\n",
            "- Smart Home Devices: ['Great, Cost-Effective Echo Device bought amazon ta...', 'Tap purchased tap thought portable speaker echo ac...']\n",
            "- General Batteries: ['Five Stars good...', 'Five Stars great...', 'Five Stars great value...']\n",
            "\n",
            "Generating blog posts...\n",
            "  Generating post for category: 'Miscellaneous Electronics'\n",
            "  Generating post for category: 'E-readers & Tablets'\n",
            "  Generating post for category: 'Smart Home Devices'\n",
            "  Generating post for category: 'General Batteries'\n",
            "\n",
            "Saving generated blog posts...\n",
            "  Saved blog post for 'Miscellaneous Electronics' to: /content/drive/MyDrive/generated_blog_posts/amazon_recommendations_miscellaneous_electronics.md\n",
            "  Saved blog post for 'E-readers & Tablets' to: /content/drive/MyDrive/generated_blog_posts/amazon_recommendations_e-readers_and_tablets.md\n",
            "  Saved blog post for 'Smart Home Devices' to: /content/drive/MyDrive/generated_blog_posts/amazon_recommendations_smart_home_devices.md\n",
            "  Saved blog post for 'General Batteries' to: /content/drive/MyDrive/generated_blog_posts/amazon_recommendations_general_batteries.md\n",
            "\n",
            "All blog posts generated and saved successfully!\n",
            "You can find them in your Google Drive at: /content/drive/MyDrive/generated_blog_posts/\n"
          ]
        }
      ]
    }
  ]
}