{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from transformers import (\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizerFast,\n",
        ")\n",
        "from functools import lru_cache\n",
        "\n",
        "# ==============================\n",
        "# 0) CONFIG\n",
        "# ==============================\n",
        "SENTIMENT_MODEL_PATH = \"/content/drive/MyDrive/models/distilbert_model\"\n",
        "CATEGORIZED_DATA_PATH = \"/content/drive/MyDrive/amazon_reviews_clustered_and_categorized.csv\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def load_df() -> pd.DataFrame:\n",
        "    df = pd.read_csv(CATEGORIZED_DATA_PATH)\n",
        "    if \"asin\" in df.columns:\n",
        "        df[\"asin\"] = df[\"asin\"].astype(str)\n",
        "    if \"full_review\" in df.columns:\n",
        "        df[\"full_review\"] = df[\"full_review\"].astype(str).fillna(\"\")\n",
        "    return df\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def load_sentiment_model():\n",
        "    tok = DistilBertTokenizerFast.from_pretrained(SENTIMENT_MODEL_PATH)\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(SENTIMENT_MODEL_PATH)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return tok, model\n",
        "\n",
        "# ==============================\n",
        "# Functions\n",
        "# ==============================\n",
        "\n",
        "def predict_sentiment_gradio(text: str, progress=gr.Progress(track_tqdm=False)) -> str:\n",
        "    if not text.strip():\n",
        "        return \"Please enter some text.\"\n",
        "    tok, model = load_sentiment_model()\n",
        "    inputs = tok(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        pred = outputs.logits.argmax(-1).item()\n",
        "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "    return labels[pred] if pred < len(labels) else str(pred)\n",
        "\n",
        "def display_category_distribution() -> str:\n",
        "    df = load_df()\n",
        "    counts = df[\"meta_category\"].value_counts().reset_index()\n",
        "    counts.columns = [\"Meta-Category\", \"Number of Reviews\"]\n",
        "    return counts.to_html(index=False)\n",
        "\n",
        "def download_category_counts() -> str:\n",
        "    df = load_df()\n",
        "    counts = df[\"meta_category\"].value_counts().reset_index()\n",
        "    counts.columns = [\"Meta-Category\", \"Number of Reviews\"]\n",
        "    path = \"/content/category_counts.csv\"\n",
        "    counts.to_csv(path, index=False)\n",
        "    return path\n",
        "\n",
        "# ==============================\n",
        "# Build UI\n",
        "# ==============================\n",
        "\n",
        "def build_ui():\n",
        "    df = load_df()\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"Amazon Review Analysis\") as demo:\n",
        "        gr.Markdown(\"# Amazon Review Sentiment Analyser\")\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Sentiment Analysis\")\n",
        "                text = gr.Textbox(lines=4, label=\"Enter Review\")\n",
        "                out = gr.Textbox(label=\"Predicted Sentiment\")\n",
        "                gr.Button(\"Analyze\").click(predict_sentiment_gradio, text, out)\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Category Overview\")\n",
        "                table = gr.HTML(display_category_distribution())\n",
        "                refresh = gr.Button(\"Refresh\")\n",
        "                csv_btn = gr.Button(\"Download CSV\")\n",
        "                csv_file = gr.File()\n",
        "                refresh.click(lambda: display_category_distribution(), None, table)\n",
        "                csv_btn.click(download_category_counts, None, csv_file)\n",
        "    return demo\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount(\"/content/drive\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    app = build_ui()\n",
        "    app.queue().launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "sBaeuFp_M0kh",
        "outputId": "f51aadd5-c9d5-4984-b9ec-c5a90e62028b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4e2dff9b4cd43388e7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4e2dff9b4cd43388e7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8856dbd90cfbb399a3.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://423750a8ff478ba34e.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://4e2dff9b4cd43388e7.gradio.live\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}